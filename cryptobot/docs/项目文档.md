# AI 智能知识库系统

## 1. 项目结构 

ai_kb/
├── data/
│   ├── knowledge_base/  # Chroma 向量数据库
│   └── pdfs/           # PDF 文件存储
├── src/
│   ├── kb/            # 知识库模块
│   │   ├── loaders/   # 加载器
│   │   │   ├── pdf_loader.py
│   │   │   └── url_loader.py
│   │   ├── knowledge_base.py
│   │   ├── knowledge_manager.py
│   │   └── clear_kb.py
│   ├── bot/           # 聊天机器人模块
│   │   └── chat.py    # 聊天核心逻辑
│   └── app.py         # Streamlit Web应用
├── docs/
│   └── 项目文档.md
└── requirements.txt    # 项目依赖

## 2. 核心功能

### 2.1 知识库管理
- 支持加载 PDF、URL 和纯文本
- 基于向量相似度的内容去重
- 支持内容搜索和相似度匹配

### 2.2 去重机制
- 使用 OpenAI Embeddings 生成文本向量
- 相似度阈值设置为 0.95
- 对所有类型内容（PDF、URL、纯文本）都有效

## 3. 关键代码

### 3.1 知识库核心 (knowledge_base.py)

class KnowledgeBase:
    def __init__(self):
        """初始化知识库"""
        self.persist_dir = "ai_kb/data/knowledge_base"
        os.makedirs(self.persist_dir, exist_ok=True)
        
        self.vectorstore = Chroma(
            persist_directory=self.persist_dir,
            embedding_function=OpenAIEmbeddings()
        )
    
    def is_content_duplicate(self, content: str, threshold: float = 0.95) -> bool:
        """检查内容是否重复"""
        try:
            collection = self.vectorstore.get()
            if len(collection['ids']) == 0:
                return False
            
            results = self.vectorstore.similarity_search_with_score(content, k=1)
            
            if results:
                doc, score = results[0]
                similarity = 1 - score
                logger.info(f"内容相似度: {similarity:.4f}")
                
                is_duplicate = similarity >= threshold
                if is_duplicate:
                    logger.info(f"内容重复 (相似度 {similarity:.4f} >= 阈值 {threshold})")
                else:
                    logger.info(f"内容不重复 (相似度 {similarity:.4f} < 阈值 {threshold})")
                
                return is_duplicate
            
            return False
            
        except Exception as e:
            logger.error(f"检查内容重复时出错: {str(e)}")
            return False

### 3.2 知识库管理器 (knowledge_manager.py)

class KnowledgeManager:
    def __init__(self):
        self.kb = KnowledgeBase()
        self.pdf_loader = PDFLoader()
        self.url_loader = URLLoader()
    
    def load_all(self, pdf_dir: str = None, urls: List[str] = None, texts: List[str] = None) -> Dict[str, int]:
        """加载所有资源"""
        results = {
            "pdfs_loaded": 0,
            "urls_loaded": 0,
            "texts_loaded": 0
        }
        
        if pdf_dir and os.path.exists(pdf_dir):
            results["pdfs_loaded"] = self.load_pdfs(pdf_dir)
                
        if urls:
            results["urls_loaded"] = self.load_urls(urls)
        
        if texts:
            results["texts_loaded"] = self.load_texts(texts)
        
        return results
### 3.3 聊天机器人 (chat.py)
### 3.3 聊天机器人 (chat.py)

class CryptoChat:
    def __init__(self):
        """初始化聊天机器人"""
        self.kb = KnowledgeBase()
        self.llm = ChatOpenAI(
            model="gpt-3.5-turbo",
            temperature=0.7
        )
        
        # 系统提示词
        self.system_prompt = """你是一个专业的加密货币和链上交易分析助手。
        你需要：
        1. 基于知识库内容提供准确的分析和建议
        2. 如果不确定，要明确说明这是推测
        3. 对于高风险操作，要提醒用户注意风险
        4. 保持专业、客观的语气
        """
        
    def _build_prompt(self, query: str, search_results: List[Dict]) -> str:
        """构建 prompt"""
        # 提取搜索结果内容
        contexts = []
        for result in search_results:
            content = result.get("content", "").strip()
            source = result.get("source", "未知来源")
            if content:
                contexts.append(f"来源: {source}\n内容: {content[:1000]}")
        
        context_text = "\n\n".join(contexts)
        
        # 构建完整 prompt
        prompt = ChatPromptTemplate.from_messages([
            ("system", self.system_prompt),
            ("system", f"基于以下参考信息回答问题:\n\n{context_text}"),
            ("user", query)
        ])
        
        return prompt
    
    def chat(self, query: str) -> str:
        """处理用户问题并返回答案"""
        try:
            logger.info(f"\n用户问题: {query}")
            
            # 1. 搜索相关内容
            search_results = self.kb.search(query, k=5)
            if not search_results:
                logger.info("没有找到相关信息")
                return "抱歉，我的知识库中没有找到相关信息。请尝试换个问题，或者等待知识库更新。"
            
            # 2. 构建 prompt
            prompt = self._build_prompt(query, search_results)
            
            # 3. 生成回答
            logger.info("生成回答...")
            response = self.llm.invoke(prompt).content
            logger.info(f"回答: {response}\n")
            
            return response
            
        except Exception as e:
            logger.error(f"处理问题时出错: {str(e)}")
            return "抱歉，处理您的问题时出现了错误。请稍后再试。"
    
    def get_sources(self, query: str) -> List[Dict]:
        """获取答案的参考来源"""
        try:
            results = self.kb.search(query, k=3)
            sources = []
            for r in results:
                source = {
                    "title": r.get("source", "未知来源"),
                    "content": r.get("content", "")[:200] + "..."
                }
                sources.append(source)
            return sources
        except Exception as e:
            logger.error(f"获取来源时出错: {str(e)}")
            return []
这个聊天机器人实现了：
基于知识库的智能问答
专业的加密货币分析
来源追踪功能
完整的错误处理
详细的日志记录



## 4. 使用说明

### 4.1 清空知识库
重要：清空知识库时，建议使用独立命令而不是在代码中调用：

python -m ai_kb.src.kb.clear_kb

### 4.2 加载内容

from ai_kb.src.kb.knowledge_manager import KnowledgeManager

manager = KnowledgeManager()

# 加载 PDF
manager.load_all(pdf_dir="ai_kb/data/pdfs")

# 加载 URL
manager.load_all(urls=["https://example.com"])

# 加载纯文本
manager.load_all(texts=["这是一段测试文本"])

### 4.3 内容去重
- 系统自动对所有新添加的内容进行去重检查
- 相似度阈值为 0.95（可配置）
- 支持跨类型去重（PDF、URL、纯文本之间互相去重）

## 5. 注意事项

1. 数据库操作
   - 清空数据库时使用独立命令
   - 避免在代码中直接调用 clear_knowledge_base()

2. 去重功能
   - 对所有类型内容都有效
   - 即使文件名不同，内容相同也会被去重
   - 可以通过调整阈值控制去重严格程度

3. 错误处理
   - 系统包含完整的错误处理和日志记录
   - 加载失败不会影响其他内容的处理

## 6. 未来优化方向

1. 性能优化
   - 批量处理大量文档
   - 并行处理多个来源

2. 功能扩展
   - 支持更多文档类型
   - 自定义去重规则
   - 内容更新机制

3. 监控和管理
   - 添加管理界面
   - 统计和分析功能
